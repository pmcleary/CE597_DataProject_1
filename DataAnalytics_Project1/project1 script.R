# the Twitter data is loaded into R
# list the column names of the imorted .csv file
Tweets2014 <- read.csv("pu2014.csv")
library(dplyr)
Tweets2014_Subset <- dplyr::select(Tweets2014,epoch,user_id,user_followers_count,user_statuses_count,)
#list the names in the new subsetted data file 
names(Tweets2014_Subset)
# checking for N/A values in the data frame
library("purrr")
# map_df applys functions to elements of a list and returns a tibble
# is.na, TRUE if an element is NA
# sum() TRUE is 1, FALSE is 0
map_df(Tweets2014_Subset, function(x) sum(is.na(x)))
# there are no N/A values in the columns
# convert epoch time to day-month-year, day of week, and local time
library('anytime')
tweetdate <- Tweets2014_Subset[[1]]
# convert Unix epoch time to Year-Month-Day and H:M:S format
dates <- anytime(tweetdate)
# Convert the format of the dates to Day-Month-Year
dmyDates <- format(dates,'%d-%m-%Y')
# convert the format of the time to Hours, Minutes, Seconds
hmstime <- format(as.POSIXct(dates, '%H:%M:%S EDT'))
# Display the day of the week of the tweet
dayofweek <- weekdays(dates)
#Final data frame of the twitter data to be used for this project
TweetData <- cbind(Tweets2014_Subset,dmyDates,hmstime,dayofweek)
# determine the number of distinct users
numdistinctusers <- sapply(TweetData, function(x) length(unique(x)))
table(numdistinctusers)
# 3204 distinct users
# count the number of tweets created by each user
tweetsbyuser <- count(TweetData, 'user_id')
# find max of col 'n' of 
apply(tweetsbyuser,2,max)
decrtweets <- tweetsbyuser[order(tweetsbyuser$freq, decreasing = TRUE),]
# make a histogram plot of the tweets by user in decreasing order
plot(log10(decrtweets$freq), type = "s",main = "Number of Tweets by User",xlab = "Users", ylab = "Number of Tweets (log10)",)
# determining the percentage of tweets generated by the top 15% of users
# 3204 total users, from dim(decrtweets), 15% of 3204 is 481, 
# determine the total number of tweets
totaltweets <- sum(decrtweets$freq)
# 68077 total tweets
# determine the top n% (15% below) of tweeters
q <- nrow(decrtweets)*0.15
# create a numeric row counter for the decrtweets data frame
decrtweets <- dplyr::mutate(decrtweets, id = row_number())
# create a subsetted data frame of the top  n% of tweeters
top15 <- subset(decrtweets, id <= q)
View(top15)
# determine the number of tweets generated by the top n% of tweeters
totaltop15 <- sum(top15$freq)
# determine the percentage of total tweets generated by the top n% of tweeters
topusers_percent_oftotal <- totaltop15/totaltweets
topusers_vec=as.vector(c(totaltweets,totaltop15)) 
# generate a barplot showing share of tweets by top users
barplotnames <- c("Total Tweets","Tweets by top 15% of Users")
barplot(topusers_vec, xlab = "Tweeters", ylab = "Number of Tweets",names.arg = barplotnames,col = "blue",main = "Share of Tweets Generated by top Users")
# the top 15% of users generate 0.835 or 84% of all tweets
#summarize the # of tweets over days of the week
library(plyr)
mondays <- ldply(TweetData, function(c) sum(c=="Monday"))
tuesdays <- ldply(TweetData, function(c) sum(c=="Tuesday"))
wednesdays <- ldply(TweetData, function(c) sum(c=="Wednesday"))
thursdays <- ldply(TweetData, function(c) sum(c=="Thursday"))
fridays <- ldply(TweetData, function(c) sum(c=="Friday"))
saturdays <- ldply(TweetData, function(c) sum(c=="Saturday"))
sundays <- ldply(TweetData, function(c) sum(c=="Sunday"))
# sum all of the tweets that occur Monday through Friday
Tweets_weekday <- mondays[7,2]+tuesdays[7,2]+wednesdays[7,2]+thursdays[7,2]+fridays[7,2]
# sum the weekend days
Tweets_weekends <- saturdays[7,2]+sundays[7,2]
# generate a plot showing the tweet patterns throughout the week
weeklydist_tweets <- as.vector(c(mondays[7,2],tuesdays[7,2],wednesdays[7,2],thursdays[7,2],fridays[7,2],saturdays[7,2],sundays[7,2])) 
View(weeklydist_tweets)
weeklabels <- c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday")
#barplot(weeklydist_tweets,main = "Tweet trends throughout the week",xlab = "Days of Week", ylab = "Number of Tweets", col = "blue", names.arg = weeklabels)
# group tweets by time of day
# use the "dates" which is in POSIXct format to extract just the hours of the time
library(lubridate)
hours <- hour(dates)
# convert integer to numeric to use with the cut function
hoursnum <- as.numeric(hours)
# bin the hours of the day
hourintervals <- cut(hoursnum, breaks= seq(0, 24, by = 1), right = FALSE)
#plot(hourintervals, type = "b",main = "Tweet trends throughout the day",xlab = "Time of Day(24H)", ylab = "Number of Tweets", col = "blue")
# calculate time interval between tweets of users
# order the data by user_id
TweetData_ord_by_userid <- TweetData[order(TweetData$user_id),]
#convert hmstime column in the data frame to a POSIX value
TweetData_ord_by_userid$epoch <- as.POSIXct(as.numeric(as.character(TweetData_ord_by_userid$epoch)),origin="1970-01-01")
#tweetfrequency <- aggregate(TweetData_ord_by_userid$epoch, list(user = TweetData_ord_by_userid$user_id), mean(diff(TweetData_ord_by_userid$epoch)))
# determine the time difference between tweets by user
View(TweetData)
Tepoch <- TweetData$epoch
Tuser <- TweetData$user_id
Tnew <- data.frame(Tepoch, Tuser)
View(Tnew)
timeint <- data.frame(diff(Tnew$Tepoch))/3600
timeint2 <- mean(timeint)
View(timeint)
Tdiff <- Tnew %>% group_by(Tuser) %>% summarize(timeint = mean((diff(Tepoch))))
intervals_vec <- log10(timespace$time_int)
hist(intervals_vec)
View(timespace)